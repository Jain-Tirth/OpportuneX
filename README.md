# OpportuneX - Multi-Platform Hackathon & Event Aggregator

A robust, full-stack application that automatically aggregates hackathons and tech events from multiple platforms including Devfolio, Unstop, Eventbrite, and Devpost. Features a modern React frontend with automated backend scraping and real-time scheduler management.

## ğŸŒŸ Features

### Backend
- **Multi-Platform Scraping**: Automated data collection from 4 major platforms
  - ğŸ† **Devfolio** - Premium hackathon platform
  - ğŸš€ **Unstop** - Competitions and hackathons  
  - ğŸ« **Eventbrite** - Event management platform
  - ğŸ’» **Devpost** - Developer showcase platform
- **Intelligent Data Processing**: Event normalization, duplicate detection, and tag extraction
- **Automated Scheduler**: Node-cron based system with start/stop/manual trigger controls
- **REST API**: Full CRUD operations with filtering capabilities
- **Database Integration**: Supabase PostgreSQL with real-time capabilities
- **Error Handling**: Robust error management and logging

### Frontend
- **Modern UI/UX**: Premium design with responsive layout
- **Event Dashboard**: Beautiful card-based event display
- **Scheduler Management**: Real-time scheduler status and controls
- **Advanced Filtering**: Search by tags, dates, and event types
- **Statistics Dashboard**: Event counts and platform insights
- **Mobile Responsive**: Optimized for all device sizes

## ğŸš€ Quick Start

### Prerequisites
- Node.js 16+ 
- npm or yarn
- Supabase account
- Git

### Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/Jain-Tirth/OpportuneX.git
   cd OpportuneX
   ```

2. **Setup Backend**
   ```bash
   cd server
   npm install
   
   # Create .env file
   cp .env.example .env
   # Add your Supabase credentials
   ```

3. **Setup Frontend**
   ```bash
   cd ../client
   npm install
   ```

4. **Configure Environment Variables**
   ```bash
   # In server/.env
   SUPABASE_URL=your_supabase_project_url
   SUPABASE_KEY=your_supabase_anon_key
   NODE_ENV=development
   ```

5. **Setup Database Schema**
   ```sql
   -- Run this in your Supabase SQL editor
   CREATE TABLE "Event" (
     id SERIAL PRIMARY KEY,
     title TEXT NOT NULL,
     description TEXT,
     type TEXT,
     "startDate" DATE,
     "endDate" DATE,
     deadline DATE,
     tags TEXT[],
     "hostedBy" TEXT,
     verified BOOLEAN DEFAULT false,
     "redirectURL" TEXT,
     created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
   );
   ```

6. **Run the Application**
   ```bash
   # Terminal 1 - Backend
   cd server
   npm start
   
   # Terminal 2 - Frontend  
   cd client
   npm start
   ```

7. **Access the Application**
   - Frontend: http://localhost:3000
   - Backend API: http://localhost:5000

## ğŸ“ Project Structure

```
OpportuneX/
â”œâ”€â”€ client/                 # React Frontend
â”‚   â”œâ”€â”€ public/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/     # Reusable UI components
â”‚   â”‚   â”‚   â”œâ”€â”€ EventCard.jsx
â”‚   â”‚   â”‚   â””â”€â”€ SchedulerDashboard.jsx
â”‚   â”‚   â”œâ”€â”€ pages/          # Page components
â”‚   â”‚   â”‚   â””â”€â”€ Home.jsx
â”‚   â”‚   â”œâ”€â”€ services/       # API integration
â”‚   â”‚   â”‚   â””â”€â”€ api.js
â”‚   â”‚   â””â”€â”€ lib/           # Utilities
â”‚   â”‚       â””â”€â”€ supaBaseClient.js
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ server/                 # Node.js Backend
â”‚   â”œâ”€â”€ controllers/        # Request handlers
â”‚   â”‚   â””â”€â”€ eventController.js
â”‚   â”œâ”€â”€ routes/            # API routes
â”‚   â”‚   â”œâ”€â”€ eventRoute.js
â”‚   â”‚   â””â”€â”€ schedulerRoute.js
â”‚   â”œâ”€â”€ scrappers/         # Web scrapers
â”‚   â”‚   â”œâ”€â”€ devfolioScraper.js
â”‚   â”‚   â”œâ”€â”€ unstopScrapper.js
â”‚   â”‚   â”œâ”€â”€ eventBriteScrapper.js
â”‚   â”‚   â”œâ”€â”€ devPostScrapper.js
â”‚   â”‚   â””â”€â”€ mainScrapping.js
â”‚   â”œâ”€â”€ supabase/          # Database config
â”‚   â”‚   â””â”€â”€ client.js
â”‚   â”œâ”€â”€ scheduler.js       # Cron job manager
â”‚   â”œâ”€â”€ server.js         # Main server file
â”‚   â””â”€â”€ package.json
â””â”€â”€ render.yaml           # Deployment config
```

## ğŸ”§ API Endpoints

### Events
- `GET /api/events` - Fetch all events
- `POST /api/events` - Create new event
- `GET /api/events/scrape` - Trigger manual scraping
- `GET /api/events/sample` - Get sample events

### Scheduler
- `GET /api/scheduler/status` - Get scheduler status
- `POST /api/scheduler/start` - Start automated scheduling
- `POST /api/scheduler/stop` - Stop automated scheduling  
- `POST /api/scheduler/trigger` - Manual scraping trigger

## ğŸ¤– Automated Scraping

The system runs automated scraping every 2 hours using node-cron:

### Scraping Features
- **Smart Filtering**: Only tech/hackathon related events
- **Date Validation**: Filters out expired events
- **Duplicate Prevention**: Title and host-based deduplication
- **Tag Extraction**: Automatic categorization with relevant tags
- **Error Recovery**: Continues scraping even if one platform fails

### Scraped Data Points
- Event title and description
- Start/end dates and deadlines
- Host organization
- Event tags and categories
- Registration URLs
- Prize information (when available)

## ğŸ¨ Frontend Features

### Components
- **EventCard**: Displays event information with beautiful styling
- **SchedulerDashboard**: Real-time scheduler management interface
- **Home**: Main dashboard with hero section and event grid

### Styling
- Modern CSS with gradients and animations
- Responsive design for mobile/tablet/desktop
- Safari compatibility optimizations
- Dark theme elements

## ğŸš€ Deployment

### Backend (Render)
The backend is configured for deployment on Render using `render.yaml`:

```yaml
# Auto-deployed from GitHub
services:
  - type: web
    name: opportunex-backend
    env: node
    buildCommand: npm install
    startCommand: npm start
```

### Frontend (Vercel)
The frontend can be deployed on Vercel:

```bash
cd client
npm run build
# Deploy to Vercel
```

### Environment Variables
Set these in your deployment platform:
- `SUPABASE_URL`
- `SUPABASE_KEY`
- `NODE_ENV=production`

## ğŸ› ï¸ Development

### Adding New Scrapers
1. Create new scraper file in `server/scrappers/`
2. Implement required methods:
   ```javascript
   class NewScraper {
     async scrapeEvents() {
       // Return array of event objects
     }
   }
   ```
3. Add to `mainScrapping.js`
4. Update scheduler if needed

### Data Schema
Events must follow this structure:
```javascript
{
  title: String,
  description: String,
  type: String,
  startDate: String (YYYY-MM-DD),
  endDate: String (YYYY-MM-DD),
  deadline: String (YYYY-MM-DD),
  tags: Array of Strings,
  hostedBy: String,
  verified: Boolean,
  redirectURL: String
}
```

## ğŸ” Monitoring & Debugging

### Logs
- Server logs include scraping progress and errors
- Each scraper provides detailed console output
- Database operations are logged with success/failure status

### Testing
```bash
# Test individual scrapers
cd server
node test-unstop-only.js
node test-devfolio-only.js

# Test full scraping process
node test-scraper.js
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open Pull Request

### Development Guidelines
- Follow existing code structure and naming conventions
- Add error handling for all external API calls
- Test scrapers with multiple platforms before submitting
- Update documentation for new features

## ğŸ“Š Platform Coverage

| Platform | Events | Status | Features |
|----------|--------|--------|----------|
| **Unstop** | ~30+ per scrape | âœ… Active | Pagination, Tag extraction |
| **Devfolio** | ~20+ per scrape | âœ… Active | XHR interception, Prize info |
| **Eventbrite** | ~15+ per scrape | âœ… Active | Location filtering, Categories |
| **Devpost** | ~10+ per scrape | âœ… Active | Challenge extraction, Tech focus |

## ğŸ› Troubleshooting

### Common Issues

1. **Supabase Connection Error**
   ```
   Error: supabaseUrl is required
   ```
   - Check `.env` file has correct SUPABASE_URL and SUPABASE_KEY
   - Ensure environment variables are loaded properly

2. **Scraper Errors**
   ```
   Cannot read properties of undefined
   ```
   - API response structure may have changed
   - Check scraper logs for specific platform errors
   - Update scraper with defensive programming

3. **CORS Issues**
   - Backend server must be running on port 5000
   - Frontend should proxy API calls correctly

## ğŸ“ˆ Future Enhancements

- [ ] Real-time notifications for new events
- [ ] User accounts and event bookmarking
- [ ] Advanced filtering and search
- [ ] Calendar integration
- [ ] Mobile app development
- [ ] AI-powered event recommendations
- [ ] Analytics dashboard for event trends

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ‘¨â€ğŸ’» Author

**Jain-Tirth**
- GitHub: [@Jain-Tirth](https://github.com/Jain-Tirth)
- Project: [OpportuneX](https://github.com/Jain-Tirth/OpportuneX)

## ğŸ™ Acknowledgments

- Built with React, Node.js, and Supabase
- Web scraping powered by Axios and Cheerio
- Scheduled tasks using node-cron
- Deployed on Render and Vercel

---

**â­ Star this repository if you find it helpful!**
